# -*- coding: utf-8 -*-
"""Fine_tuning_a_TTS_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pCxmZgtQBKtwvsPVboJGwQ5-pqVSd34P
"""

!pip install transformers datasets[audio] SentencePiece  soundfile speechbrain accelerate

from huggingface_hub import notebook_login
from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, Seq2SeqTrainingArguments, Seq2SeqTrainer, SpeechT5HifiGan, AutoTokenizer
from datasets import load_dataset, DatasetDict, Audio

"""Notebook login"""

notebook_login()

"""Pre-processing"""

checkpoint = "microsoft/speecht5_tts"
model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)
processor = SpeechT5Processor.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

"""Dataset processing"""

dataset = load_dataset("mozilla-foundation/common_voice_13_0", "ur", split='train')
dataset[0]

dataset

# # Define a function to resample the audio data to the desired sampling rate (e.g., 16k)
# def resample_audio(example):
#     audio, _ = librosa.load(example["path"], sr=16000)
#     return {**example, "audio": audio}

# # Apply the resampling function to the "audio" column for all splits
# for split in dataset.keys():
#     dataset[split] = dataset[split].map(resample_audio)

# dataset = dataset.map(lambda example: {"audio": (example["audio"], 16000)}, remove_columns=["audio"])

# Unable to change the sampling_rate = 16000
# Tried different methods but unable to set the value
# This can affect the training of our model

# This method is not working
dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))

dataset[0]

# # Remove specific subsets
# subsets_to_remove = ["test", "other", "invalidated"]
# for subset in subsets_to_remove:
#     dataset.pop(subset, None)

"""Text cleanup for SpeechT5 tokenization"""

tokenizer = processor.tokenizer

buck2uni = {
            u"\u0627":"A",
            u"\u0627":"A",
            u"\u0675":"A",
            u"\u0673":"A",
            u"\u0630":"A",
            u"\u0622":"AA",
            u"\u0628":"B",
            u"\u067E":"P",
            u"\u062A":"T",
            u"\u0637":"T",
            u"\u0679":"T",
            u"\u062C":"J",
            u"\u0633":"S",
            u"\u062B":"S",
            u"\u0635":"S",
            u"\u0686":"CH",
            u"\u062D":"H",
            u"\u0647":"H",
            u"\u0629":"H",
            u"\u06DF":"H",
            u"\u062E":"KH",
            u"\u062F":"D",
            u"\u0688":"D",
            u"\u0630":"Z",
            u"\u0632":"Z",
            u"\u0636":"Z",
            u"\u0638":"Z",
            u"\u068E":"Z",
            u"\u0631":"R",
            u"\u0691":"R",
            u"\u0634":"SH",
            u"\u063A":"GH",
            u"\u0641":"F",
            u"\u06A9":"K",
            u"\u0642":"K",
            u"\u06AF":"G",
            u"\u0644":"L",
            u"\u0645":"M",
            u"\u0646":"N",
            u"\u06BA":"N",
            u"\u0648":"O",
            u"\u0649":"Y",
            u"\u0626":"Y",
            u"\u06CC":"Y",
            u"\u06D2":"E",
            u"\u06C1":"H",
            u"\u064A":"E"  ,
            u"\u06C2":"AH"  ,
            u"\u06BE":"H"  ,
            u"\u0639":"A"  ,
            u"\u0643":"K" ,
            u"\u0621":"A",
            u"\u0624":"O",
            u"\u0648":"U",
            u"\u060C":"" #seperator ulta comma
}
def transString(string, reverse=0):
    '''Given a Unicode string, transliterate into Buckwalter. To go from
    Buckwalter back to Unicode, set reverse=1'''
    for k, v in buck2uni.items():
      if not reverse:
            string = string.replace(k, v)
      else:
            string = string.replace(v, k)
    return string
print(dataset[0]["sentence"])
print(transString(dataset[0]["sentence"]))

def prepare_dataset(batch):
  """Function to preprocess the dataset with the .map method"""
  transcription = transString(batch["sentence"])

  if transcription.startswith('"') and transcription.endswith('"'):
    # we can remove trailing quotation marks as they do not affect the transcription
    transcription = transcription[1:-1]

  if transcription[-1] not in [".", "?", "!"]:
    # append a full-stop to sentences that do not end in punctuation
    transcription = transcription + "."

  batch["sentence"] = transcription

  return batch

dataset = dataset.map(prepare_dataset, desc="preprocess dataset")
dataset

"""Replacing characters that are unknown in the to be trained language"""

dataset[0]

"""Speaker embeddings"""

import torch
from speechbrain.pretrained import EncoderClassifier
import os

spk_model_name = "speechbrain/spkrec-xvect-voxceleb"

device = "cuda" if torch.cuda.is_available() else "cpu"
speaker_model = EncoderClassifier.from_hparams(
    source=spk_model_name,
    run_opts={"device": device},
    savedir=os.path.join("/tmp", spk_model_name),
)


def create_speaker_embedding(waveform):
    with torch.no_grad():
        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))
        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)
        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()
    return speaker_embeddings

"""Processing the dataset"""

def prepare_dataset(example):
    audio = example["audio"]

    example = processor(
        text=example["sentence"],
        audio_target=audio["array"],
        sampling_rate=audio["sampling_rate"],
        return_attention_mask=False,
    )

    # strip off the batch dimension
    example["labels"] = example["labels"][0]

    # use SpeechBrain to obtain x-vector
    example["speaker_embeddings"] = create_speaker_embedding(audio["array"])

    return example

"""Mapping the dataset"""

dataset = dataset.map(prepare_dataset)
dataset

def is_not_too_long(input_ids):
    input_length = len(input_ids)
    return input_length < 200


dataset = dataset.filter(is_not_too_long, input_columns=["input_ids"])
len(dataset)

dataset = dataset.train_test_split(test_size=0.1)
dataset

"""Data collator"""

from dataclasses import dataclass
from typing import Any, Dict, List, Union

@dataclass
class TTSDataCollatorWithPadding:
    processor: Any

    def __call__(
        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]
    ) -> Dict[str, torch.Tensor]:
        input_ids = [{"input_ids": feature["input_ids"]} for feature in features]
        label_features = [{"input_values": feature["labels"]} for feature in features]
        speaker_features = [feature["speaker_embeddings"] for feature in features]

        # collate the inputs and targets into a batch
        batch = processor.pad(
            input_ids=input_ids, labels=label_features, return_tensors="pt"
        )

        # replace padding with -100 to ignore loss correctly
        batch["labels"] = batch["labels"].masked_fill(
            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100
        )

        # not used during fine-tuning
        del batch["decoder_attention_mask"]

        # round down target lengths to multiple of reduction factor
        if model.config.reduction_factor > 1:
            target_lengths = torch.tensor(
                [len(feature["input_values"]) for feature in label_features]
            )
            target_lengths = target_lengths.new(
                [
                    length - length % model.config.reduction_factor
                    for length in target_lengths
                ]
            )
            max_length = max(target_lengths)
            batch["labels"] = batch["labels"][:, :max_length]

        # also add in the speaker embeddings
        batch["speaker_embeddings"] = torch.tensor(speaker_features)

        return batch

data_collator = TTSDataCollatorWithPadding(processor=processor)

"""Traing the model"""

from functools import partial

# disable cache during training since it's incompatible with gradient checkpointing
model.config.use_cache = False

# set language and task for generation and re-enable cache
model.generate = partial(model.generate, use_cache=True)

"""Training arguments"""

training_args = Seq2SeqTrainingArguments(
    output_dir="urdu_tts_finetuned_voxpopuli_nl",  # change to a repo name of your choice
    per_device_train_batch_size=4,
    gradient_accumulation_steps=8,
    learning_rate=1e-5,
    warmup_steps=500,
    max_steps=4000,
    gradient_checkpointing=True,
    fp16=True,
    evaluation_strategy="steps",
    per_device_eval_batch_size=2,
    save_steps=1000,
    eval_steps=1000,
    logging_steps=25,
    report_to=["tensorboard"],
    load_best_model_at_end=True,
    greater_is_better=False,
    label_names=["labels"],
    push_to_hub=True,
)

"""Trainer"""

trainer = Seq2SeqTrainer(
    args=training_args,
    model=model,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    data_collator=data_collator,
    tokenizer=processor,
)

trainer.train()

trainer.push_to_hub()

"""Inference"""

model = SpeechT5ForTextToSpeech.from_pretrained(
    "ahmadaarif/urdu_tts_finetuned_voxpopuli_nl"
)

example = dataset["test"][304]
speaker_embeddings = torch.tensor(example["speaker_embeddings"]).unsqueeze(0)

text = "MRA NAM AHMAD HA"

inputs = processor(text=text, return_tensors="pt")

vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
speech = model.generate_speech(inputs["input_ids"], speaker_embeddings, vocoder=vocoder)

"""Audio Inference"""

from IPython.display import Audio
import numpy as np

Audio(speech.numpy(), rate=16000)

"""Interface"""

!pip install gradio
import gradio as gr

def predict(input_text):
  output = trainer.predict(input_text)
  return output

interface = gr.Interface(fn=predict, inputs="text", outputs="audio", verbose = True, title="Text to Speech for Urdu",
                         description = "An Urdu Text to Speech application. It can produce random noise  as well as the accuracy is around 47%. It can be fine-tuned further as well. Right now it works successfully on very basic urdu text, such the ones in the example.")
interface.launch(inline=False, debug=True, share=True)